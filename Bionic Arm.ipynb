{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0858e5-b53e-4813-90c8-ead022b5b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Discretized AP Arrays (0->+max->0->-max->0)\n",
    "\n",
    "ap_typeI = np.array(\n",
    "    [0.0, 0.4, 0.9, 1.0, 0.7, 0.2, 0.0, -0.2,\n",
    "     -0.5, -0.7, -0.5, -0.3, -0.1, 0.0, 0.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "ap_typeIIa = np.array(\n",
    "    [0.0, 0.7, 1.0, 0.4, 0.0, -0.3, -0.7, -0.3, 0.0, 0.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "ap_typeIIb = np.array(\n",
    "    [0.0, 1.0, 0.3, 0.0, -0.5, -0.2, 0.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "ap_silence = np.array(\n",
    "    [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "# 1) Feature Definitions & Dilation/Padding (First Layer)\n",
    "\n",
    "sampling_rate = 20000                                           #20 kHz\n",
    "\n",
    "features = [\n",
    "    {\"name\": \"Type I\",   \"frequency\": 30,  \"kernel_size\": 15},  # Slow Twitch\n",
    "    {\"name\": \"Type IIa\", \"frequency\": 100, \"kernel_size\": 10},  # Medium Twitch\n",
    "    {\"name\": \"Type IIb\", \"frequency\": 225, \"kernel_size\": 7 },  # Fast Twitch\n",
    "    {\"name\": \"Silence\",  \"frequency\": None,\"kernel_size\": 7 }   # Silence => size=7\n",
    "]\n",
    "\n",
    "# Function to compute dilation rates and padding for each feature\n",
    "\n",
    "def compute_dilations_and_padding(feature, sampling_rate, num_layers=4):\n",
    "    ksize = feature[\"kernel_size\"]\n",
    "    if feature[\"frequency\"] is None:                            # Silence feature\n",
    "        dilation_rates = [1]*num_layers                         # Fixed dilation\n",
    "    else:\n",
    "        freq = feature[\"frequency\"]\n",
    "        d0 = int(np.ceil(sampling_rate/(freq*ksize)))           # Base dilation\n",
    "        dilation_rates = [d0]\n",
    "        for _ in range(num_layers-1):                           # Double dilation for each subsequent layer\n",
    "            dilation_rates.append(dilation_rates[-1]*2)\n",
    "    total_pad = sum((ksize-1)*d for d in dilation_rates)        # Total padding\n",
    "    return dilation_rates, total_pad\n",
    "\n",
    "for feat in features:\n",
    "    feat[\"dilation_rates\"], feat[\"total_padding\"] = compute_dilations_and_padding(feat,sampling_rate)\n",
    "\n",
    "# 2) First Layer Processing (Feature Extraction for 4 layers)\n",
    "\n",
    "def first_layer_processing(input_data, num_channels=4):\n",
    "    signal_length = input_data.shape[1]                        # Length of the signal\n",
    "    num_features = len(features)                               # Number of features (4 in this case)\n",
    "    channel_list = []\n",
    "    ap_kernels = {\n",
    "        \"Type I\":   tf.keras.initializers.Constant(ap_typeI.reshape((15,1,1))),\n",
    "        \"Type IIa\": tf.keras.initializers.Constant(ap_typeIIa.reshape((10,1,1))),\n",
    "        \"Type IIb\": tf.keras.initializers.Constant(ap_typeIIb.reshape((7,1,1))),\n",
    "        \"Silence\":  tf.keras.initializers.Constant(ap_silence.reshape((7,1,1)))\n",
    "    }\n",
    "    for ch in range(num_channels):\n",
    "        ch_data = input_data[ch,:]                            # Extract data for this channel\n",
    "        feat_outputs = []\n",
    "        for feat in features:\n",
    "            ksize = feat[\"kernel_size\"]\n",
    "            dilations = feat[\"dilation_rates\"]\n",
    "            total_pad = feat[\"total_padding\"]\n",
    "            feat_name = feat[\"name\"]\n",
    "            x = tf.reshape(ch_data, (1, signal_length, 1))    # Reshape data and apply causal padding\n",
    "            x = tf.pad(x, [[0, 0],[total_pad,0],[0, 0]], mode=\"CONSTANT\")                                               \n",
    "            for d in dilations:                               # Apply convolutional layers with increasing dilation\n",
    "                init = ap_kernels[feat_name]\n",
    "                conv = tf.keras.layers.Conv1D(\n",
    "                    filters=1, \n",
    "                    kernel_size=ksize, \n",
    "                    dilation_rate=d,\n",
    "                    padding=\"valid\", \n",
    "                    activation=None,\n",
    "                    use_bias=False,\n",
    "                    kernel_initializer=init,\n",
    "                    trainable=False\n",
    "                )\n",
    "                x = conv(x)\n",
    "                out_1d = tf.squeeze(x).numpy()                # Convert back to numpy\n",
    "                feat_outputs.append(out_1d)\n",
    "        min_len = min(len(a) for a in feat_outputs)           # Align features by trimming to the minimum length\n",
    "        feat_outputs = [a[:min_len] for a in feat_outputs]\n",
    "        stacked = np.stack(feat_outputs, axis=0)\n",
    "        channel_list.append(stacked) \n",
    "    min_len_overall = min(x.shape[1] for x in channel_list)   # Align channels and stack into a final tensor\n",
    "    channel_list = [x[:, :min_len_overall] for x in channel_list]\n",
    "    first_out = np.stack(channel_list, axis=0)                # => (4,4,time_steps)\n",
    "    return first_out\n",
    "\n",
    "# 3) Second Layer Processing with 2 sub-layers (dilations=10,20) + Feature Stride\n",
    "\n",
    "def second_layer_processing_with_strides(first_out, strides_per_feature, num_filters=4):\n",
    "    kernel_size=10                                            # Fixed kernel size for this layer\n",
    "    second_layer_dilations = [10,20]                          # Fixed dilation rates for all features\n",
    "    num_channels, num_features, time_steps = first_out.shape\n",
    "    second_list = []\n",
    "    for ch in range(num_channels):\n",
    "        for j in range(num_features):\n",
    "            data_1d = first_out[ch, j, :]\n",
    "            data_3d = tf.reshape(data_1d, (1, time_steps, 1))\n",
    "            stride = strides_per_feature[j]\n",
    "            x = data_3d                                            \n",
    "            for d in second_layer_dilations:                  # Two convolutional layers with increasing dilation\n",
    "                conv = tf.keras.layers.Conv1D(\n",
    "                    filters=num_filters, \n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=stride,\n",
    "                    dilation_rate=d,\n",
    "                    padding=\"same\",\n",
    "                    activation=\"relu\"\n",
    "                )\n",
    "                x = conv(x)\n",
    "            second_list.append(x.numpy())\n",
    "second_array = np.array(second_list)\n",
    "new_times = [second_array[i].shape[1] for i in range(len(second_array))]\n",
    "min_nt = min(new_times)\n",
    "trimmed = []\n",
    "idx = 0\n",
    "for ch in range(num_channels):\n",
    "    for j in range(num_features):\n",
    "        arr = second_array[idx]\n",
    "        arr = arr[:, :min_nt, :]\n",
    "        trimmed.append(arr)\n",
    "        idx += 1\n",
    "trimmed_np = np.array(trimmed)\n",
    "trimmed_np = trimmed_np.reshape(num_channels,num_features, 1,min_nt, num_filters)\n",
    "final_tensor = np.squeeze(trimmed_np, axis=2).transpose(0,1,3,2)\n",
    "return final_tensor\n",
    "\n",
    "# 4)  MLP For Servo Angle Prediction Output\n",
    "\n",
    "def build_servo_mlp(input_dim, num_outputs=5):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_outputs, activation=None)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 5) Full Pipeline with previous angles concatenation\n",
    "\n",
    "def process_test_data(custom_test_data=None, signal_length=1000, num_channels=4, num_filters=4, prev_angles=None):\n",
    "    if custom_test_data is None:\n",
    "        input_data = tf.random.uniform((num_channels, signal_length))\n",
    "    else:\n",
    "        input_data = tf.convert_to_tensor(custom_test_data, dtype=tf.float32)\n",
    "        \n",
    "    first_out = first_layer_processing(input_data,num_channels=num_channels)        # First-layer processing      \n",
    "    \n",
    "    second_layer_strides = [1, 2, 3, 1]                                             # Second-layer processing\n",
    "    second_out = second_layer_processing_with_strides(first_out, strides_per_feature=second_layer_strides,num_filters=num_filters)\n",
    "    \n",
    "    flattened_out = second_out.reshape((1, -1))                                     # Flatten the output for MLP input\n",
    "    \n",
    "    input_dim = flattened_out.shape[1]                                              # Build and run the MLP\n",
    "    servo_mlp = build_servo_mlp(input_dim=input_dim, num_outputs=5)\n",
    "    raw_angles = servo_mlp.predict(flattened_out,[0])\n",
    "\n",
    "    clamped_angles = np.clip(raw_angles, 0, 180)                                    # Clamp angles between 0 and 180 degrees                                \n",
    "\n",
    "return second_out, clamped_angles\n",
    "\n",
    "# 6) Example Usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data = np.random.rand(4, 1000).astype(np.float32)                          # Example test data: 4 channels, each with 1000 samples\n",
    "    \n",
    "    second_out, angles = process_test_data(custom_test_data=test_data)              # Run the pipeline\n",
    "\n",
    "    print(\"Predicted Servo Angles:\", angles)                                        # Print final servo angles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474e36b-31ac-4120-aef0-ccab225c9753",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
