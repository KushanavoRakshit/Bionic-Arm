{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b74f6b-7e4c-48a7-8894-ab1e219046d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D93ABF6480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Predicted Servo Angles: [[131.56909  180.         0.         0.        37.196495]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Discretized AP Arrays (0->+max->0->-max->0)\n",
    "\n",
    "ap_typeI = np.array(\n",
    "    [0.0, 0.4, 0.9, 1.0, 0.7, 0.2, 0.0, -0.2,\n",
    "     -0.5, -0.7, -0.5, -0.3, -0.1, 0.0, 0.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "ap_typeIIa = np.array(\n",
    "    [0.0, 0.7, 1.0, 0.4, 0.0, -0.3, -0.7, -0.3, 0.0, 0.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "ap_typeIIb = np.array(\n",
    "    [0.0, 1.0, 0.3, 0.0, -0.5, -0.2, 0.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "ap_silence = np.array(\n",
    "    [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "    dtype=np.float32)\n",
    "\n",
    "# 1) Feature Definitions & Dilation/Padding (First Layer)\n",
    "\n",
    "sampling_rate = 20000                                           #20 kHz\n",
    "\n",
    "features = [\n",
    "    {\"name\": \"Type I\",   \"frequency\": 30,  \"kernel_size\": 15},  # Slow Twitch\n",
    "    {\"name\": \"Type IIa\", \"frequency\": 100, \"kernel_size\": 10},  # Medium Twitch\n",
    "    {\"name\": \"Type IIb\", \"frequency\": 225, \"kernel_size\": 7 },  # Fast Twitch\n",
    "    {\"name\": \"Silence\",  \"frequency\": None,\"kernel_size\": 7 }   # Silence => size=7\n",
    "]\n",
    "\n",
    "# Function to compute dilation rates and padding for each feature\n",
    "\n",
    "def compute_dilations_and_padding(feature, sampling_rate, num_layers=4):\n",
    "    ksize = feature[\"kernel_size\"]\n",
    "    if feature[\"frequency\"] is None:                            # Silence feature\n",
    "        dilation_rates = [1]*num_layers                         # Fixed dilation\n",
    "    else:\n",
    "        freq = feature[\"frequency\"]\n",
    "        d0 = int(np.ceil(sampling_rate/(freq*ksize)))           # Base dilation\n",
    "        dilation_rates = [d0]\n",
    "        for _ in range(num_layers-1):                           # Double dilation for each subsequent layer\n",
    "            dilation_rates.append(dilation_rates[-1]*2)\n",
    "    total_pad = sum((ksize-1)*d for d in dilation_rates)        # Total padding\n",
    "    return dilation_rates, total_pad\n",
    "\n",
    "for feat in features:\n",
    "    feat[\"dilation_rates\"], feat[\"total_padding\"] = compute_dilations_and_padding(feat,sampling_rate)\n",
    "\n",
    "# 2) First Layer Processing (Feature Extraction for 4 layers)\n",
    "\n",
    "def first_layer_processing(input_data, num_channels=4):\n",
    "    signal_length = input_data.shape[1]                        # Length of the signal\n",
    "    num_features = len(features)                               # Number of features (4 in this case)\n",
    "    channel_list = []\n",
    "    ap_kernels = {\n",
    "        \"Type I\":   tf.keras.initializers.Constant(ap_typeI.reshape((15,1,1))),\n",
    "        \"Type IIa\": tf.keras.initializers.Constant(ap_typeIIa.reshape((10,1,1))),\n",
    "        \"Type IIb\": tf.keras.initializers.Constant(ap_typeIIb.reshape((7,1,1))),\n",
    "        \"Silence\":  tf.keras.initializers.Constant(ap_silence.reshape((7,1,1)))\n",
    "    }\n",
    "    for ch in range(num_channels):\n",
    "        ch_data = input_data[ch,:]                            # Extract data for this channel\n",
    "        feat_outputs = []\n",
    "        for feat in features:\n",
    "            ksize = feat[\"kernel_size\"]\n",
    "            dilations = feat[\"dilation_rates\"]\n",
    "            total_pad = feat[\"total_padding\"]\n",
    "            feat_name = feat[\"name\"]\n",
    "            x = tf.reshape(ch_data, (1, signal_length, 1))    # Reshape data and apply causal padding\n",
    "            x = tf.pad(x, [[0, 0],[total_pad,0],[0, 0]], mode=\"CONSTANT\")                                               \n",
    "            for d in dilations:                               # Apply convolutional layers with increasing dilation\n",
    "                init = ap_kernels[feat_name]\n",
    "                conv = tf.keras.layers.Conv1D(\n",
    "                    filters=1, \n",
    "                    kernel_size=ksize, \n",
    "                    dilation_rate=d,\n",
    "                    padding=\"valid\", \n",
    "                    activation=None,\n",
    "                    use_bias=False,\n",
    "                    kernel_initializer=init,\n",
    "                    trainable=False\n",
    "                )\n",
    "                x = conv(x)\n",
    "                out_1d = tf.squeeze(x).numpy()                # Convert back to numpy\n",
    "                feat_outputs.append(out_1d)\n",
    "        min_len = min(len(a) for a in feat_outputs)           # Align features by trimming to the minimum length\n",
    "        feat_outputs = [a[:min_len] for a in feat_outputs]\n",
    "        stacked = np.stack(feat_outputs, axis=0)\n",
    "        channel_list.append(stacked) \n",
    "    min_len_overall = min(x.shape[1] for x in channel_list)   # Align channels and stack into a final tensor\n",
    "    channel_list = [x[:, :min_len_overall] for x in channel_list]\n",
    "    first_out = np.stack(channel_list, axis=0)                # => (4,4,time_steps)\n",
    "    return first_out\n",
    "\n",
    "# 3) Second Layer Processing with 2 sub-layers (dilations=10,20) + Feature Stride\n",
    "def second_layer_processing_with_strides(first_out, strides_per_feature, num_filters=4):\n",
    "    kernel_size=10                                            # Fixed kernel size for this layer\n",
    "    second_layer_dilations = [10,20]                          # Fixed dilation rates for all features\n",
    "    num_channels, num_features, time_steps = first_out.shape\n",
    "    second_list = []                                           # Initialize second_list within the function\n",
    "    for ch in range(num_channels):\n",
    "        for j in range(num_features):\n",
    "            data_1d = first_out[ch, j, :]\n",
    "            data_3d = tf.reshape(data_1d, (1, time_steps, 1))\n",
    "            stride = strides_per_feature[j] if j < len(strides_per_feature) else 1\n",
    "            x = data_3d                                            \n",
    "            for d in second_layer_dilations: \n",
    "                stride = 1 if d > 1 else strides_per_feature[j] if j < len(strides_per_feature) else 1      # Two convolutional layers with increasing dilation\n",
    "                conv = tf.keras.layers.Conv1D(\n",
    "                    filters=num_filters, \n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=stride,\n",
    "                    dilation_rate=d,\n",
    "                    padding=\"same\",\n",
    "                    activation=\"relu\"\n",
    "                )\n",
    "                x = conv(x)\n",
    "            second_list.append(x.numpy())\n",
    "    second_array = np.array(second_list)\n",
    "    new_times = [second_array[i].shape[1] for i in range(len(second_array))]\n",
    "    min_nt = min(new_times)\n",
    "    trimmed = []\n",
    "    idx = 0\n",
    "    for ch in range(num_channels):\n",
    "        for j in range(num_features):\n",
    "            arr = second_array[idx]\n",
    "            arr = arr[:, :min_nt, :]\n",
    "            trimmed.append(arr)\n",
    "            idx += 1\n",
    "    trimmed_np = np.array(trimmed)\n",
    "    trimmed_np = trimmed_np.reshape(num_channels,num_features, 1,min_nt, num_filters)\n",
    "    final_tensor = np.squeeze(trimmed_np, axis=2).transpose(0,1,3,2)\n",
    "    return final_tensor # Return the final tensor\n",
    "\n",
    "# 4)  MLP For Servo Angle Prediction Output\n",
    "\n",
    "def build_servo_mlp(input_dim, num_outputs=5):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_outputs, activation=None)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 5) Full Pipeline with previous angles concatenation\n",
    "\n",
    "def process_test_data(custom_test_data=None, signal_length=1000, num_channels=4, num_filters=4, prev_angles=None):\n",
    "    if custom_test_data is None:\n",
    "        input_data = tf.random.uniform((num_channels, signal_length))\n",
    "    else:\n",
    "        input_data = tf.convert_to_tensor(custom_test_data, dtype=tf.float32)\n",
    "        \n",
    "    first_out = first_layer_processing(input_data,num_channels=num_channels)        # First-layer processing      \n",
    "    \n",
    "    second_layer_strides = [1, 2, 3, 1]                                             # Second-layer processing\n",
    "    second_out = second_layer_processing_with_strides(first_out, strides_per_feature=second_layer_strides,num_filters=num_filters)\n",
    "    \n",
    "    flattened_out = second_out.reshape((1, -1))                                     # Flatten the output for MLP input\n",
    "    \n",
    "    input_dim = flattened_out.shape[1]                                              # Build and run the MLP\n",
    "    servo_mlp = build_servo_mlp(input_dim=input_dim, num_outputs=5)\n",
    "    raw_angles = servo_mlp.predict(flattened_out)\n",
    "\n",
    "    clamped_angles = np.clip(raw_angles, 0, 180)                                    # Clamp angles between 0 and 180 degrees                                \n",
    "\n",
    "    return second_out, clamped_angles\n",
    "\n",
    "# 6) Example Usage\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_data = np.random.rand(4, 1000).astype(np.float32)                          # Example test data: 4 channels, each with 1000 samples\n",
    "    \n",
    "    second_out, angles = process_test_data(custom_test_data=test_data)              # Run the pipeline\n",
    "\n",
    "    print(\"Predicted Servo Angles:\", angles)                                        # Print final servo angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d296d-5869-4480-89e6-1c3ffc972d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
